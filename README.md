# CMDR-IAD

**CMDR-IAD: Cross-Modal Mapping and Dual-Branch Reconstruction for 2Dâ€“3D Industrial Anomaly Detection**

This repository provides the official PyTorch implementation of **CMDR-IAD**, an unsupervised framework for industrial anomaly detection that integrates RGB appearance and 3D surface geometry.  
The method is lightweight, does not rely on memory banks or teacherâ€“student architectures, and supports multimodal (2D+3D) as well as single-modality (2D-only or 3D-only) settings.

---

## ðŸ“Œ Overview

Multimodal industrial anomaly detection benefits from combining complementary RGB and 3D information. However, existing unsupervised approaches often depend on memory banks, teacherâ€“student schemes, or fragile fusion strategies, which can degrade performance under noisy depth, weak texture, or missing modalities.

**CMDR-IAD** addresses these challenges through:
- **Bidirectional 2Dâ†”3D cross-modal mapping** to model appearanceâ€“geometry consistency
- **Dual-branch reconstruction** to independently capture normal appearance and geometric patterns
- **A reliability- and confidence-aware fusion strategy** for robust and precise anomaly localization

---

## ðŸ“‘ Table of Contents
- [Introduction](#introduction)
- [Datasets](#datasets)
- [Checkpoints](#checkpoints)
- [Code](#code)
- [Contacts](#contacts)

## Introduction
...

## Datasets

We evaluate CMDR-IAD on the **[MVTec 3D-AD](https://www.mvtec.com/company/research/datasets/mvtec-3d-ad)** dataset, which provides paired RGB images and 3D point clouds for industrial anomaly detection.

The raw dataset requires preprocessing to obtain aligned RGB images and organized point clouds. The necessary preprocessing scripts are provided in the `processing` directory.



## ðŸ“¦ checkpoints

We release the pretrained CMDR-IAD checkpoints used to obtain the results reported in the paper.
The weights are provided per object category and can be directly used for inference.

- Download: [CMDR-IAD checkpoints â€“ link to be added]

## Code
To train CMDR-IAD, use the train.py script.
The training procedure independently optimizes the cross-modal mapping networks and the dual-branch reconstruction modules for a given object category, following the protocol described in the paper.
Training command
python train.py --class_name tire

Training options

--dataset_path : Path to the root directory of the MVTec 3D-AD dataset.

--checkpoint_savepath : Directory where trained checkpoints will be saved (default: ./checkpoints/CMDR_IAD_checkpoints).

--class_name : Object category to train on.

--epochs_no : Number of training epochs.

--batch_size : Batch size.

Each object category is trained independently, and the resulting checkpoints are stored per class.

## Contacts
...



---

## ðŸ“‚ Repository Structure

```text
CMDR-IAD/
â”œâ”€â”€ networks/
â”‚   â”œâ”€â”€ features.py
â”‚   â”œâ”€â”€ Map.py
â”‚   â”œâ”€â”€ Dec2d.py
â”‚   â”œâ”€â”€ Dec3d.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â””â”€â”€ full_models.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ mvtec3d_utils.py
â”‚   â”œâ”€â”€ pointnet2_utils.py
â”‚   â”œâ”€â”€ metrics_utils.py
â”‚   â””â”€â”€ general_utils.py
â”‚
â”œâ”€â”€ train.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE
